<!DOCTYPE html>
<html lang="en">
<link href="https://fonts.maateen.me/bensen/font.css" rel="stylesheet">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Start your development with Meyawo landing page.">
    <meta name="author" content="Devcrud">
    <title>ORCA</title>
    <!-- font icons -->
    <link rel="stylesheet" href="assets/vendors/themify-icons/css/themify-icons.css">
    <!-- Bootstrap + Meyawo main styles -->
    <link rel="stylesheet" href="assets/css/meyawo.css">
</head>
<body>
<!-- Page Header -->
   <header class="header header-mini">
      <div class="header-title">Overview Retriever with Clustering Augmentation</div>
      <nav aria-label="breadcrumb">
         <ol class="breadcrumb">
            <li class="breadcrumb-item"><a href="index.html">Home</a></li>
         </ol>
      </nav>
   </header> <!-- End Of Page Header -->

<div class="container">
    <hr>
    <p>Dense Passage Retrieval (DPR) models are a family of neural retrievers, employing only the encoder part
        of a Transformer architecture like BERT to encode queries and short text documents into a shared latent vector
        space. In this context, the notion of relevance is captured through the distance metric defined in that shared
        vector space. Typically, DPR models are trained using a ranking or
        retrieval objective. However, in this study, we demonstrate that for specific retrieval scenarios, such as
        overview passage retrieval, these models can be enhanced by incorporating an additional clustering objective that
        leverages query-specific subtopic information.</p>

    <p>In the realm of information retrieval, many queries encompass a wide array of subtopics. Addressing this complexity,
        we introduce Topic-Mono-BERT, a model that seamlessly integrates neural ranking and query-specific clustering to
        enhance the relevance and coherence of search results. Our model is built on the hypothesis that embeddings designed
        to cluster topically similar content together will inherently improve ranking accuracy. This synergy between
        clustering and ranking leads to more relevant and comprehensive search results. Our extensive evaluations on two
        publicly available passage retrieval datasets demonstrate a remarkable 16% improvement in the identification of
        relevant overview passages.
    </p>

    <p><b>Paper:</b> <a href="https://dl.acm.org/doi/10.1145/3574318.3574336">Topic-Mono-BERT: A Joint Retrieval-Clustering System for Retrieving Overview Passages</a> </p>
    <p><b>Github repo:</b> <a href="https://github.com/nihilistsumo/ORCA">ORCA</a> </p>
</div>

</body>
</html>